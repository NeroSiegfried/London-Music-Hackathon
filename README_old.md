# ABRSM AI Music Feedback System ğŸ¼

**Enhanced Competition-Ready Version - London Music Technology Hackathon 2025**

A comprehensive AI system that analyzes music performances and provides constructive feedback, combining advanced audio signal processing with large language models to support music education. Now featuring **sheet music visualization**, **time signature analysis**, and **polyphonic music support**.

## ğŸ¯ Challenge Brief

ABRSM (The Associated Board of the Royal Schools of Music) challenged us to explore how AI can support music education by building a system that generates feedback on music performances, combining audio analysis and language modeling to create scalable tools for music assessment.

## âœ¨ Features

### **Core Analysis Engine**
- **Real-time Audio Analysis**: Extracts pitch, timing, and rhythmic information
- **Multiple Pieces Support**: "Twinkle, Twinkle, Little Star" and "Mary Had a Little Lamb"
- **AI-Powered Feedback**: Uses Google's Gemini API for personalized feedback
- **Self-Contained References**: Automatically generates MIDI and audio references

### **ğŸ†• Enhanced Features**
- **ğŸ“Š Sheet Music Visualization**: Visual comparison showing reference vs performance on staff notation
- **â±ï¸ Time Signature Analysis**: Detects time signatures, analyzes beat patterns, and timing compensation
- **ğŸ¹ Polyphonic Music Support**: Handles multiple simultaneous notes (piano, chords, harmonies)
- **ğŸ“ˆ Advanced Visualizations**: Timing charts, rhythm analysis, and difference highlighting
- **ğŸ” Voice Leading Analysis**: For complex harmonic content
- **ğŸ¯ Complexity Scoring**: Automatic difficulty assessment

### **Professional Features**
- **Multiple Analysis Modes**: Simple, Enhanced, or Custom configurations
- **Demo Mode**: Built-in demo functionality for easy testing
- **Professional CLI**: Extensive command-line options
- **Error Resilience**: Comprehensive error handling and validation

## ğŸš€ Quick Start

### **ğŸ–¥ï¸ GUI Interface (Recommended)**
```bash
# Setup and launch interactive GUI
source venv/bin/activate
python launch_gui.py
```

**GUI Features:**
- **ğŸ“Š Interactive Analysis**: Visual overview of performance metrics
- **ğŸ¼ Sheet Music View**: Reference vs performance comparison with error highlighting  
- **â±ï¸ Timing Analysis**: Beat patterns and tempo analysis
- **ğŸµ Note-by-Note Analysis**: Detailed breakdown of each note with accuracy scoring
- **ğŸ¤– AI Feedback**: Integrated LLM feedback generation
- **ğŸ“ File Management**: Easy audio file loading and analysis export

### Demo Mode (Command Line)
```bash
# Setup
source venv/bin/activate
export GOOGLE_API_KEY='your_api_key_here'

# Run enhanced demo with all features
python enhanced_main.py --enhanced --demo
```

### Enhanced Analysis (Your Own Recording)
```bash
# Full analysis with visualizations
python enhanced_main.py --enhanced my_performance.wav

# Simple analysis only
python enhanced_main.py --simple my_performance.wav

# Analysis without visualizations
python enhanced_main.py --no-visualizations my_performance.wav
```

## ğŸ›  Installation

1. **Quick Setup:**
   ```bash
   ./setup.sh
   ```

2. **Manual Setup:**
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   pip install -r requirements.txt
   ```

3. **Get Google AI Studio API Key:**
   - Visit [Google AI Studio](https://aistudio.google.com/)
   - Create a new API key
   - Set environment variable: `export GOOGLE_API_KEY='your_key_here'`

## ğŸ“Š How It Works

### **1. Reference Generation**
- Creates "perfect" MIDI and synthesized audio versions
- Enhanced synthesis with harmonics and natural envelopes
- Multiple pieces supported with easy extensibility

### **2. Performance Analysis**
- **Pitch Extraction**: librosa's PYIN algorithm for robust pitch tracking
- **Onset Detection**: Multiple methods for rhythm analysis
- **Polyphonic Detection**: Handles multiple simultaneous pitches
- **Time Signature Detection**: Automatic rhythm pattern recognition

### **3. Intelligent Comparison**
- **Smart Alignment**: Matches performed notes with reference notes
- **Multi-dimensional Analysis**: Pitch (cents), timing (ms), rhythm patterns
- **Voice Separation**: Melody vs harmony analysis for complex pieces
- **Beat Analysis**: Strong vs weak beat accuracy

### **4. Enhanced Visualization**
- **Sheet Music Generation**: Visual staff notation with differences highlighted
- **Timing Charts**: Beat consistency and rhythm pattern analysis
- **Difference Maps**: Color-coded accuracy indicators

### **5. AI Feedback Generation**
- **Context-Aware Prompts**: Incorporates timing and complexity analysis
- **Educational Focus**: Constructive, encouraging feedback
- **Technical Translation**: Converts analysis data to musical language

## ğŸ“ˆ Technical Architecture

```
Audio Input â†’ Multi-Modal Analysis â†’ Feature Extraction â†’ Visualization Generation
     â†“              â†“                     â†“                     â†“
Monophonic     Polyphonic         Time Signature      Sheet Music + Charts
Analysis    â†’   Analysis      â†’    Analysis      â†’     Visual Comparison
     â†“              â†“                     â†“                     â†“
         Comprehensive JSON Report â†’ Enhanced LLM Prompt â†’ Natural Language Feedback
```

## ğŸµ Analysis Capabilities

### **Monophonic Analysis** (Single melody line)
- âœ… Pitch accuracy (measured in cents)
- âœ… Timing precision (measured in milliseconds)  
- âœ… Note completion rate
- âœ… Rhythm pattern adherence

### **ğŸ†• Polyphonic Analysis** (Multiple simultaneous notes)
- âœ… Chord progression detection
- âœ… Voice leading analysis
- âœ… Melody vs harmony separation
- âœ… Complexity scoring (0-100)
- âœ… Multi-pitch onset detection

### **ğŸ†• Time Signature Analysis**
- âœ… Automatic time signature detection (4/4, 3/4, 2/4, etc.)
- âœ… Strong vs weak beat accuracy
- âœ… Timing compensation detection
- âœ… Beat consistency scoring
- âœ… Rhythmic difficulty assessment

### **ğŸ†• Visual Analysis**
- âœ… Sheet music notation generation
- âœ… Reference vs performance comparison
- âœ… Color-coded accuracy indicators
- âœ… Timing deviation charts
- âœ… Beat pattern visualizations

## ï¿½ Supported Content

### **Built-in Pieces**
- **Twinkle, Twinkle, Little Star** (`--piece twinkle`) - Beginner level
- **Mary Had a Little Lamb** (`--piece mary`) - Elementary level

### **Music Complexity Support**
- **Simple Melodies**: Single note sequences âœ…
- **Piano Pieces**: Multiple simultaneous notes âœ…
- **Chord Progressions**: Harmonic analysis âœ…
- **Mixed Textures**: Melody + accompaniment âœ…

*New pieces can be easily added by extending the PIECES dictionary*

## ğŸ† Competition Advantages

### **Creativity & Innovation (25%)**
- âœ… Novel AI + traditional music analysis combination
- âœ… Self-generating reference system for portability
- âœ… First music feedback system with visual sheet music diff
- âœ… Polyphonic analysis capability unique in hackathon context

### **Technical Execution (25%)**
- âœ… Industry-standard audio processing (librosa, scipy)
- âœ… Robust error handling and comprehensive validation
- âœ… Professional CLI with extensive options
- âœ… Modular architecture enabling easy extension

### **Impact & Usefulness (25%)**
- âœ… Directly addresses ABRSM's scalable assessment needs
- âœ… Handles both simple and complex musical content
- âœ… Visual feedback aids learning and engagement
- âœ… Ready for integration into existing educational platforms

### **Presentation (25%)**
- âœ… Comprehensive documentation with examples
- âœ… Interactive demo mode requiring no external files
- âœ… Professional project structure and code quality
- âœ… Multiple visualization outputs for compelling demonstrations

## ğŸ”§ Advanced Usage

### **Command Line Options**
```bash
# Enhanced analysis with all features
python enhanced_main.py --enhanced my_performance.wav

# Specific piece analysis
python enhanced_main.py --piece mary --enhanced my_performance.wav

# Simple analysis (original functionality)
python enhanced_main.py --simple my_performance.wav

# Analysis without LLM feedback
python enhanced_main.py --no-llm my_performance.wav

# Skip visualizations (faster processing)
python enhanced_main.py --no-visualizations my_performance.wav

# Demo mode
python enhanced_main.py --demo

# Create demo audio file only
python enhanced_main.py --create-demo-only
```

### **Integration Example**
```python
from enhanced_main import MusicAnalyzer

analyzer = MusicAnalyzer(piece_key="twinkle")
f0, times, onsets, enhanced_analysis = analyzer.analyze_with_enhancements(
    "performance.wav", 
    generate_visualizations=True,
    detect_polyphony=True,
    analyze_timing=True
)
```

## ğŸ“ Example Enhanced Output

```
ğŸ¼ ABRSM AI Music Feedback System
   Analyzing: Twinkle, Twinkle, Little Star
   Audio: demo_performance.wav
   Mode: Enhanced Analysis with Visualizations
==================================================

ï¿½ ENHANCED ANALYSIS FEATURES
==================================================

â±ï¸  Time Signature Analysis:
   â€¢ Detected: (4, 4)
   â€¢ Tempo: 100 BPM
   â€¢ Beat Consistency: 85.2%
   â€¢ Difficulty: Beginner - Most common time signature
   â€¢ Timing chart saved: timing_analysis.png

ğŸ¹ Polyphonic Content Detected:
   â€¢ Complexity: 45.2/100
   â€¢ Difficulty: Intermediate - Multi-voice texture
   â€¢ Avg Simultaneous Notes: 2.3
   â€¢ Chord Changes: 4

ğŸ¼ Sheet Music Analysis:
   â€¢ Visual comparison saved: sheet_music_analysis.png

ğŸ¯ YOUR PERSONALIZED FEEDBACK
==================================================
Great job on your performance! You maintained a steady rhythm throughout most of the piece and your pitch accuracy was quite good. I particularly noticed your strong beat placement in the first half.

For your next practice session, focus on the timing in measures 3-4 where you rushed slightly, and work on the pitch accuracy in the final phrase where a couple notes were a bit flat. The visual analysis shows exactly where to concentrate your practice.

Keep up the excellent work - your musical expression is developing beautifully!

ğŸ“ Generated Files:
   â€¢ timing_analysis.png
   â€¢ sheet_music_analysis.png
```

## ğŸš€ Future Enhancements

- **Real-time Analysis**: Live feedback during performance
- **Extended Repertoire**: Classical pieces, scales, arpeggios
- **Web Interface**: Browser-based GUI for easier access
- **Advanced Metrics**: Dynamics, articulation, expression analysis
- **Multi-instrument Support**: Guitar, violin, voice recognition
- **Progress Tracking**: Long-term improvement monitoring
- **Collaborative Features**: Teacher-student interaction tools

## ğŸ‘¥ Team

**Victor Nabasu** - Full Stack Developer & Music Technology Enthusiast
- Audio signal processing implementation
- AI integration and prompt engineering  
- Visualization system development
- CLI and user experience design

## ğŸ“„ Technical Requirements

- **Python 3.8+**
- **Audio Libraries**: librosa, scipy, numpy
- **Visualization**: matplotlib  
- **AI Integration**: Google Gemini API
- **Audio Formats**: WAV, MP3, FLAC supported
- **Output Formats**: JSON reports, PNG visualizations

## ğŸ“„ License

This project is shared with ABRSM as per the challenge requirements. Code is available for educational and research purposes.

---

*Built for the London Music Technology Hackathon 2025 - ABRSM Challenge*  
*Advancing music education through AI innovation* ğŸµ
